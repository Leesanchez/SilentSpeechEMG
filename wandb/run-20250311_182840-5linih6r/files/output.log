Epoch 1/100:   0%|                                                            | 0/3 [00:12<?, ?it/s]

Input shapes:
EMG batch shape: torch.Size([32, 8, 67])
Labels batch shape: torch.Size([32, 5])
Traceback (most recent call last):
  File "/Users/anthony-leesanchez/Desktop/silent_speech/train.py", line 314, in <module>
    main()
  File "/Users/anthony-leesanchez/Desktop/silent_speech/train.py", line 311, in main
    train_model(model, train_loader, val_loader, device=device)
  File "/Users/anthony-leesanchez/Desktop/silent_speech/train.py", line 181, in train_model
    outputs = model(batch_emg)
  File "/Users/anthony-leesanchez/Desktop/silent_speech/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/anthony-leesanchez/Desktop/silent_speech/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/anthony-leesanchez/Desktop/silent_speech/spatiotemporal_model.py", line 125, in forward
    x = self.cnn(x)  # (batch, 256, time)
  File "/Users/anthony-leesanchez/Desktop/silent_speech/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/anthony-leesanchez/Desktop/silent_speech/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/anthony-leesanchez/Desktop/silent_speech/spatiotemporal_model.py", line 68, in forward
    x = self.temporal_block1(x) + res1
  File "/Users/anthony-leesanchez/Desktop/silent_speech/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/anthony-leesanchez/Desktop/silent_speech/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/anthony-leesanchez/Desktop/silent_speech/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/Users/anthony-leesanchez/Desktop/silent_speech/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/anthony-leesanchez/Desktop/silent_speech/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/anthony-leesanchez/Desktop/silent_speech/.venv/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 217, in forward
    return F.layer_norm(
  File "/Users/anthony-leesanchez/Desktop/silent_speech/.venv/lib/python3.9/site-packages/torch/nn/functional.py", line 2910, in layer_norm
    return torch.layer_norm(
RuntimeError: Given normalized_shape=[64, 128], expected input with shape [*, 64, 128], but got input of size[32, 64, 67]
